{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "Extract all textual informations from official and government statements on the Responsibility to Protect (R2P) as found on https://www.globalr2p.org/resources/?s&filter%5B0%5D=official-statement&filter%5B1%5D=government-statement&tax=resource_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Scraping\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Data sheets \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect direct download links for every available statement\n",
    "\n",
    "Go through every page of results for https://www.globalr2p.org/resources/?s&filter%5B0%5D=official-statement&filter%5B1%5D=government-statement&tax=resource_type.\n",
    "\n",
    " - For every result, follow the link in the \"Title section\"\n",
    " - On the page we and on, look for a download link.\n",
    " - Store that download link and the cells in the table row in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only speeches from years earlier than this will be downloaded. Set to `None` if you want to include all speeches\n",
    "max_year = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\tPage 1\t---\n",
      "Skipping since entry is from year 2020.\n",
      "---\tPage 2\t---\n",
      "---\tPage 3\t---\n",
      "---\tPage 4\t---\n",
      "Could not find an English link at https://www.globalr2p.org/resources/statement-by-the-un-special-adviser-on-the-prevention-of-genocide-on-his-visit-to-the-central-african-republic-october-2017/. Will use first link available: Statement by the UN Special Adviser on the Prevention of Genocide on his visit to the Central African Republic, October 2017 [EN]\n",
      "---\tPage 5\t---\n",
      "---\tPage 6\t---\n",
      "---\tPage 7\t---\n",
      "---\tPage 8\t---\n",
      "---\tPage 9\t---\n",
      "---\tPage 10\t---\n",
      "---\tPage 11\t---\n",
      "---\tPage 12\t---\n",
      "Could not find an English link at https://www.globalr2p.org/resources/statement-by-thailand-at-the-2017-un-general-assembly-informal-interactive-dialogue-on-the-responsibility-to-protect/. Will use first link available: Download PDF Version\n",
      "---\tPage 13\t---\n",
      "Could not find download links at https://www.globalr2p.org/resources/opening-ceremony-statement-by-un-assistant-secretary-general-fabrizio-hochschild-at-the-7th-annual-meeting-of-the-global-network-of-r2p-focal-points/\n",
      "---\tPage 14\t---\n",
      "---\tPage 15\t---\n",
      "---\tPage 16\t---\n",
      "---\tPage 17\t---\n",
      "---\tPage 18\t---\n",
      "---\tPage 19\t---\n",
      "---\tPage 20\t---\n",
      "---\tPage 21\t---\n",
      "---\tPage 22\t---\n",
      "Could not find download links at https://www.globalr2p.org/resources/statement-by-volker-turk-assistant-high-commissioner-for-protection-at-the-un-refugee-agency-to-the-global-network-of-r2p-focal-points-6th-annual-meeting/\n",
      "---\tPage 23\t---\n",
      "Could not find download links at https://www.globalr2p.org/resources/opening-statement-by-un-secretary-general-ban-ki-moon-at-the-6th-annual-meeting-of-the-global-network-of-r2p-focal-points/\n",
      "Could not find download links at https://www.globalr2p.org/resources/statement-delivered-on-behalf-of-the-group-of-friends-of-r2p-at-the-32nd-session-of-the-human-rights-council/\n",
      "---\tPage 24\t---\n",
      "---\tPage 25\t---\n",
      "---\tPage 26\t---\n",
      "---\tPage 27\t---\n",
      "---\tPage 28\t---\n",
      "---\tPage 29\t---\n",
      "---\tPage 30\t---\n",
      "---\tPage 31\t---\n",
      "---\tPage 32\t---\n",
      "---\tPage 33\t---\n",
      "---\tPage 34\t---\n",
      "---\tPage 35\t---\n",
      "---\tPage 36\t---\n",
      "Could not find download links at https://www.globalr2p.org/resources/joint-statement-on-renewed-attacks-against-the-civilian-population-especially-women-and-children-in-the-widening-armed-conflict-in-south-sudan/\n",
      "---\tPage 37\t---\n",
      "---\tPage 38\t---\n",
      "---\tPage 39\t---\n",
      "---\tPage 40\t---\n",
      "Could not find an English link at https://www.globalr2p.org/resources/statement-by-brazil-at-the-2014-un-general-assembly-informal-interactive-dialogue-on-the-responsibility-to-protect/. Will use first link available: Download Prepared Version\n",
      "---\tPage 41\t---\n",
      "---\tPage 42\t---\n",
      "---\tPage 43\t---\n",
      "---\tPage 44\t---\n",
      "---\tPage 45\t---\n",
      "---\tPage 46\t---\n",
      "---\tPage 47\t---\n",
      "---\tPage 48\t---\n",
      "Got status code 404. Stopping.\n",
      "CPU times: user 22.2 s, sys: 508 ms, total: 22.7 s\n",
      "Wall time: 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fake user agent, otherwise we get a 403\n",
    "request_headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "data = []\n",
    "headers = None\n",
    "\n",
    "# Collect all links to pages with links to files for a particular speech\n",
    "# Process pages in turn until we get a non-200 response\n",
    "page = 0\n",
    "while True:\n",
    "    page += 1\n",
    "    print(f\"---\\tPage {page}\\t---\")\n",
    "\n",
    "    url = f\"https://www.globalr2p.org/resources/page/{page}/?s&filter[0]=official-statement&filter[1]=government-statement&tax=resource_type\"\n",
    "    resp = get(url, headers=request_headers)\n",
    "    \n",
    "    if not resp.status_code == 200:\n",
    "        print(f\"Got status code {resp.status_code}. Stopping.\")\n",
    "        break\n",
    "    \n",
    "    # Parse HTML in response\n",
    "    raw_html = resp.content\n",
    "    soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "    \n",
    "    table = soup.find(\"table\")\n",
    "    table_rows = table.find_all(\"tr\")\n",
    "              \n",
    "    if headers is None:\n",
    "        headers = list(h.text for h in table_rows[0].find_all(\"th\"))\n",
    "        headers.append(\"link\")\n",
    "    \n",
    "    for table_row in table_rows[1:]:\n",
    "        data_row = list(cell.text.strip() for cell in table_row.find_all(\"td\"))\n",
    "        # Get the link to the page with downloads\n",
    "        link_to_download_page = table_row.find(\"a\").attrs[\"href\"]\n",
    "        \n",
    "        # Go to download page, get link to English version if available\n",
    "        resp_down = get(link_to_download_page, headers=request_headers)\n",
    "        \n",
    "        if not resp_down.status_code == 200:\n",
    "            print(f\"Failed to fetch download page for {data_row} on page {page}\")\n",
    "            continue\n",
    "        \n",
    "        # Parse response and get all links\n",
    "        dp_soup = BeautifulSoup(resp_down.content, 'html.parser')\n",
    "        download_links = dp_soup.find_all(rel=\"download\")\n",
    "        \n",
    "        if len(download_links) < 1:\n",
    "            print(f\"Could not find download links at {link_to_download_page}\")\n",
    "            continue\n",
    "        \n",
    "        # We want a link to an English version, if available. If only one link present, use that    \n",
    "        correct_link = None\n",
    "        if len(download_links) == 1:\n",
    "            correct_link = download_links[0].attrs[\"href\"]\n",
    "        else:\n",
    "            for link in download_links:\n",
    "                if \"english\" in link.text.lower():\n",
    "                    correct_link = link.attrs[\"href\"]\n",
    "        \n",
    "        if correct_link is None:\n",
    "            print(f\"Could not find an English link at {link_to_download_page}. Will use first link available: \"\n",
    "                  f\"{download_links[0].text.strip()}\")\n",
    "            correct_link = download_links[0].attrs[\"href\"]\n",
    "        \n",
    "        data_row.append(correct_link)\n",
    "        \n",
    "        year = int(data_row[2][-4:])\n",
    "        if max_year and year >= max_year:\n",
    "            print(f\"Skipping since entry is from year {year}.\")\n",
    "            continue\n",
    "            \n",
    "        data.append(data_row)\n",
    "\n",
    "# Add unique IDs to every data row\n",
    "headers.append(\"id\")\n",
    "for i, row in enumerate(data):\n",
    "    row.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and save documents\n",
    "\n",
    "Once we have collected all the links, we download each document in turn. Documents are stored in files called `<document-id>.pdf` where `document-id` is a numerical identifier assigned to each document when collecting the download links in the step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and save a PDF in one line\n",
    "def save_pdf(url, filepath, **request_kwargs):\n",
    "    with open(filepath, 'wb') as fp:\n",
    "        fp.write(get(url, **request_kwargs).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directory structure\n",
    "MAIN_DIR = \".\"\n",
    "\n",
    "DATA_DIR = os.path.join(MAIN_DIR, 'data')\n",
    "GR2P_DIR = os.path.join(DATA_DIR, \"gr2p\")\n",
    "RAW_DIR = os.path.join(GR2P_DIR, \"pdf\")\n",
    "\n",
    "if os.path.exists(RAW_DIR):\n",
    "    shutil.rmtree(RAW_DIR)\n",
    "os.makedirs(RAW_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1 out of 461\n",
      "Downloading 2 out of 461\n",
      "Downloading 3 out of 461\n",
      "Downloading 4 out of 461\n",
      "Downloading 5 out of 461\n",
      "Downloading 6 out of 461\n",
      "Downloading 7 out of 461\n",
      "Downloading 8 out of 461\n",
      "Downloading 9 out of 461\n",
      "Downloading 10 out of 461\n",
      "Downloading 11 out of 461\n",
      "Downloading 12 out of 461\n",
      "Downloading 13 out of 461\n",
      "Downloading 14 out of 461\n",
      "Downloading 15 out of 461\n",
      "Downloading 16 out of 461\n",
      "Downloading 17 out of 461\n",
      "Downloading 18 out of 461\n",
      "Downloading 19 out of 461\n",
      "Downloading 20 out of 461\n",
      "Downloading 21 out of 461\n",
      "Downloading 22 out of 461\n",
      "Downloading 23 out of 461\n",
      "Downloading 24 out of 461\n",
      "Downloading 25 out of 461\n",
      "Downloading 26 out of 461\n",
      "Downloading 27 out of 461\n",
      "Downloading 28 out of 461\n",
      "Downloading 29 out of 461\n",
      "Downloading 30 out of 461\n",
      "Downloading 31 out of 461\n",
      "Downloading 32 out of 461\n",
      "Downloading 33 out of 461\n",
      "Downloading 34 out of 461\n",
      "Downloading 35 out of 461\n",
      "Downloading 36 out of 461\n",
      "Downloading 37 out of 461\n",
      "Downloading 38 out of 461\n",
      "Downloading 39 out of 461\n",
      "Downloading 40 out of 461\n",
      "Downloading 41 out of 461\n",
      "Downloading 42 out of 461\n",
      "Downloading 43 out of 461\n",
      "Downloading 44 out of 461\n",
      "Downloading 45 out of 461\n",
      "Downloading 46 out of 461\n",
      "Downloading 47 out of 461\n",
      "Downloading 48 out of 461\n",
      "Downloading 49 out of 461\n",
      "Downloading 50 out of 461\n",
      "Downloading 51 out of 461\n",
      "Downloading 52 out of 461\n",
      "Downloading 53 out of 461\n",
      "Downloading 54 out of 461\n",
      "Downloading 55 out of 461\n",
      "Downloading 56 out of 461\n",
      "Downloading 57 out of 461\n",
      "Downloading 58 out of 461\n",
      "Downloading 59 out of 461\n",
      "Downloading 60 out of 461\n",
      "Downloading 61 out of 461\n",
      "Downloading 62 out of 461\n",
      "Downloading 63 out of 461\n",
      "Downloading 64 out of 461\n",
      "Downloading 65 out of 461\n",
      "Downloading 66 out of 461\n",
      "Downloading 67 out of 461\n",
      "Downloading 68 out of 461\n",
      "Downloading 69 out of 461\n",
      "Downloading 70 out of 461\n",
      "Downloading 71 out of 461\n",
      "Downloading 72 out of 461\n",
      "Downloading 73 out of 461\n",
      "Downloading 74 out of 461\n",
      "Downloading 75 out of 461\n",
      "Downloading 76 out of 461\n",
      "Downloading 77 out of 461\n",
      "Downloading 78 out of 461\n",
      "Downloading 79 out of 461\n",
      "Downloading 80 out of 461\n",
      "Downloading 81 out of 461\n",
      "Downloading 82 out of 461\n",
      "Downloading 83 out of 461\n",
      "Downloading 84 out of 461\n",
      "Downloading 85 out of 461\n",
      "Downloading 86 out of 461\n",
      "Downloading 87 out of 461\n",
      "Downloading 88 out of 461\n",
      "Downloading 89 out of 461\n",
      "Downloading 90 out of 461\n",
      "Downloading 91 out of 461\n",
      "Downloading 92 out of 461\n",
      "Downloading 93 out of 461\n",
      "Downloading 94 out of 461\n",
      "Downloading 95 out of 461\n",
      "Downloading 96 out of 461\n",
      "Downloading 97 out of 461\n",
      "Downloading 98 out of 461\n",
      "Downloading 99 out of 461\n",
      "Downloading 100 out of 461\n",
      "Downloading 101 out of 461\n",
      "Downloading 102 out of 461\n",
      "Downloading 103 out of 461\n",
      "Downloading 104 out of 461\n",
      "Downloading 105 out of 461\n",
      "Downloading 106 out of 461\n",
      "Downloading 107 out of 461\n",
      "Downloading 108 out of 461\n",
      "Downloading 109 out of 461\n",
      "Downloading 110 out of 461\n",
      "Downloading 111 out of 461\n",
      "Downloading 112 out of 461\n",
      "Downloading 113 out of 461\n",
      "Downloading 114 out of 461\n",
      "Downloading 115 out of 461\n",
      "Downloading 116 out of 461\n",
      "Downloading 117 out of 461\n",
      "Downloading 118 out of 461\n",
      "Downloading 119 out of 461\n",
      "Downloading 120 out of 461\n",
      "Downloading 121 out of 461\n",
      "Downloading 122 out of 461\n",
      "Downloading 123 out of 461\n",
      "Downloading 124 out of 461\n",
      "Downloading 125 out of 461\n",
      "Downloading 126 out of 461\n",
      "Downloading 127 out of 461\n",
      "Downloading 128 out of 461\n",
      "Downloading 129 out of 461\n",
      "Downloading 130 out of 461\n",
      "Downloading 131 out of 461\n",
      "Downloading 132 out of 461\n",
      "Downloading 133 out of 461\n",
      "Downloading 134 out of 461\n",
      "Downloading 135 out of 461\n",
      "Downloading 136 out of 461\n",
      "Downloading 137 out of 461\n",
      "Downloading 138 out of 461\n",
      "Downloading 139 out of 461\n",
      "Downloading 140 out of 461\n",
      "Downloading 141 out of 461\n",
      "Downloading 142 out of 461\n",
      "Downloading 143 out of 461\n",
      "Downloading 144 out of 461\n",
      "Downloading 145 out of 461\n",
      "Downloading 146 out of 461\n",
      "Downloading 147 out of 461\n",
      "Downloading 148 out of 461\n",
      "Downloading 149 out of 461\n",
      "Could not download and save for ID 148,  : Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
      "Downloading 150 out of 461\n",
      "Downloading 151 out of 461\n",
      "Downloading 152 out of 461\n",
      "Downloading 153 out of 461\n",
      "Downloading 154 out of 461\n",
      "Downloading 155 out of 461\n",
      "Downloading 156 out of 461\n",
      "Downloading 157 out of 461\n",
      "Downloading 158 out of 461\n",
      "Downloading 159 out of 461\n",
      "Downloading 160 out of 461\n",
      "Downloading 161 out of 461\n",
      "Downloading 162 out of 461\n",
      "Downloading 163 out of 461\n",
      "Downloading 164 out of 461\n",
      "Downloading 165 out of 461\n",
      "Downloading 166 out of 461\n",
      "Downloading 167 out of 461\n",
      "Downloading 168 out of 461\n",
      "Downloading 169 out of 461\n",
      "Downloading 170 out of 461\n",
      "Downloading 171 out of 461\n",
      "Could not download and save for ID 170,  : Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
      "Downloading 172 out of 461\n",
      "Downloading 173 out of 461\n",
      "Downloading 174 out of 461\n",
      "Downloading 175 out of 461\n",
      "Downloading 176 out of 461\n",
      "Downloading 177 out of 461\n",
      "Downloading 178 out of 461\n",
      "Downloading 179 out of 461\n",
      "Downloading 180 out of 461\n",
      "Downloading 181 out of 461\n",
      "Downloading 182 out of 461\n",
      "Downloading 183 out of 461\n",
      "Downloading 184 out of 461\n",
      "Downloading 185 out of 461\n",
      "Downloading 186 out of 461\n",
      "Downloading 187 out of 461\n",
      "Downloading 188 out of 461\n",
      "Downloading 189 out of 461\n",
      "Downloading 190 out of 461\n",
      "Downloading 191 out of 461\n",
      "Downloading 192 out of 461\n",
      "Downloading 193 out of 461\n",
      "Downloading 194 out of 461\n",
      "Downloading 195 out of 461\n",
      "Downloading 196 out of 461\n",
      "Downloading 197 out of 461\n",
      "Downloading 198 out of 461\n",
      "Downloading 199 out of 461\n",
      "Downloading 200 out of 461\n",
      "Downloading 201 out of 461\n",
      "Downloading 202 out of 461\n",
      "Downloading 203 out of 461\n",
      "Downloading 204 out of 461\n",
      "Downloading 205 out of 461\n",
      "Downloading 206 out of 461\n",
      "Downloading 207 out of 461\n",
      "Downloading 208 out of 461\n",
      "Downloading 209 out of 461\n",
      "Downloading 210 out of 461\n",
      "Downloading 211 out of 461\n",
      "Downloading 212 out of 461\n",
      "Downloading 213 out of 461\n",
      "Downloading 214 out of 461\n",
      "Downloading 215 out of 461\n",
      "Downloading 216 out of 461\n",
      "Downloading 217 out of 461\n",
      "Downloading 218 out of 461\n",
      "Downloading 219 out of 461\n",
      "Downloading 220 out of 461\n",
      "Downloading 221 out of 461\n",
      "Downloading 222 out of 461\n",
      "Downloading 223 out of 461\n",
      "Downloading 224 out of 461\n",
      "Downloading 225 out of 461\n",
      "Downloading 226 out of 461\n",
      "Downloading 227 out of 461\n",
      "Downloading 228 out of 461\n",
      "Downloading 229 out of 461\n",
      "Downloading 230 out of 461\n",
      "Downloading 231 out of 461\n",
      "Downloading 232 out of 461\n",
      "Downloading 233 out of 461\n",
      "Downloading 234 out of 461\n",
      "Downloading 235 out of 461\n",
      "Downloading 236 out of 461\n",
      "Downloading 237 out of 461\n",
      "Downloading 238 out of 461\n",
      "Downloading 239 out of 461\n",
      "Downloading 240 out of 461\n",
      "Downloading 241 out of 461\n",
      "Downloading 242 out of 461\n",
      "Downloading 243 out of 461\n",
      "Downloading 244 out of 461\n",
      "Downloading 245 out of 461\n",
      "Downloading 246 out of 461\n",
      "Downloading 247 out of 461\n",
      "Downloading 248 out of 461\n",
      "Downloading 249 out of 461\n",
      "Downloading 250 out of 461\n",
      "Downloading 251 out of 461\n",
      "Downloading 252 out of 461\n",
      "Downloading 253 out of 461\n",
      "Downloading 254 out of 461\n",
      "Downloading 255 out of 461\n",
      "Downloading 256 out of 461\n",
      "Downloading 257 out of 461\n",
      "Downloading 258 out of 461\n",
      "Downloading 259 out of 461\n",
      "Downloading 260 out of 461\n",
      "Downloading 261 out of 461\n",
      "Downloading 262 out of 461\n",
      "Downloading 263 out of 461\n",
      "Downloading 264 out of 461\n",
      "Downloading 265 out of 461\n",
      "Downloading 266 out of 461\n",
      "Downloading 267 out of 461\n",
      "Downloading 268 out of 461\n",
      "Downloading 269 out of 461\n",
      "Downloading 270 out of 461\n",
      "Downloading 271 out of 461\n",
      "Downloading 272 out of 461\n",
      "Downloading 273 out of 461\n",
      "Downloading 274 out of 461\n",
      "Downloading 275 out of 461\n",
      "Downloading 276 out of 461\n",
      "Downloading 277 out of 461\n",
      "Downloading 278 out of 461\n",
      "Downloading 279 out of 461\n",
      "Downloading 280 out of 461\n",
      "Downloading 281 out of 461\n",
      "Downloading 282 out of 461\n",
      "Downloading 283 out of 461\n",
      "Downloading 284 out of 461\n",
      "Downloading 285 out of 461\n",
      "Downloading 286 out of 461\n",
      "Downloading 287 out of 461\n",
      "Downloading 288 out of 461\n",
      "Downloading 289 out of 461\n",
      "Downloading 290 out of 461\n",
      "Downloading 291 out of 461\n",
      "Downloading 292 out of 461\n",
      "Downloading 293 out of 461\n",
      "Downloading 294 out of 461\n",
      "Downloading 295 out of 461\n",
      "Downloading 296 out of 461\n",
      "Downloading 297 out of 461\n",
      "Downloading 298 out of 461\n",
      "Downloading 299 out of 461\n",
      "Downloading 300 out of 461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 301 out of 461\n",
      "Downloading 302 out of 461\n",
      "Downloading 303 out of 461\n",
      "Downloading 304 out of 461\n",
      "Downloading 305 out of 461\n",
      "Downloading 306 out of 461\n",
      "Downloading 307 out of 461\n",
      "Downloading 308 out of 461\n",
      "Downloading 309 out of 461\n",
      "Downloading 310 out of 461\n",
      "Downloading 311 out of 461\n",
      "Downloading 312 out of 461\n",
      "Downloading 313 out of 461\n",
      "Downloading 314 out of 461\n",
      "Downloading 315 out of 461\n",
      "Downloading 316 out of 461\n",
      "Downloading 317 out of 461\n",
      "Downloading 318 out of 461\n",
      "Downloading 319 out of 461\n",
      "Downloading 320 out of 461\n",
      "Downloading 321 out of 461\n",
      "Downloading 322 out of 461\n",
      "Downloading 323 out of 461\n",
      "Downloading 324 out of 461\n",
      "Downloading 325 out of 461\n",
      "Downloading 326 out of 461\n",
      "Downloading 327 out of 461\n",
      "Downloading 328 out of 461\n",
      "Downloading 329 out of 461\n",
      "Downloading 330 out of 461\n",
      "Downloading 331 out of 461\n",
      "Downloading 332 out of 461\n",
      "Downloading 333 out of 461\n",
      "Downloading 334 out of 461\n",
      "Downloading 335 out of 461\n",
      "Downloading 336 out of 461\n",
      "Downloading 337 out of 461\n",
      "Downloading 338 out of 461\n",
      "Downloading 339 out of 461\n",
      "Downloading 340 out of 461\n",
      "Downloading 341 out of 461\n",
      "Downloading 342 out of 461\n",
      "Downloading 343 out of 461\n",
      "Downloading 344 out of 461\n",
      "Downloading 345 out of 461\n",
      "Downloading 346 out of 461\n",
      "Downloading 347 out of 461\n",
      "Downloading 348 out of 461\n",
      "Downloading 349 out of 461\n",
      "Downloading 350 out of 461\n",
      "Downloading 351 out of 461\n",
      "Downloading 352 out of 461\n",
      "Downloading 353 out of 461\n",
      "Downloading 354 out of 461\n",
      "Downloading 355 out of 461\n",
      "Downloading 356 out of 461\n",
      "Downloading 357 out of 461\n",
      "Downloading 358 out of 461\n",
      "Downloading 359 out of 461\n",
      "Downloading 360 out of 461\n",
      "Downloading 361 out of 461\n",
      "Downloading 362 out of 461\n",
      "Downloading 363 out of 461\n",
      "Downloading 364 out of 461\n",
      "Downloading 365 out of 461\n",
      "Downloading 366 out of 461\n",
      "Downloading 367 out of 461\n",
      "Downloading 368 out of 461\n",
      "Downloading 369 out of 461\n",
      "Downloading 370 out of 461\n",
      "Downloading 371 out of 461\n",
      "Downloading 372 out of 461\n",
      "Downloading 373 out of 461\n",
      "Downloading 374 out of 461\n",
      "Downloading 375 out of 461\n",
      "Downloading 376 out of 461\n",
      "Downloading 377 out of 461\n",
      "Downloading 378 out of 461\n",
      "Downloading 379 out of 461\n",
      "Downloading 380 out of 461\n",
      "Downloading 381 out of 461\n",
      "Downloading 382 out of 461\n",
      "Downloading 383 out of 461\n",
      "Downloading 384 out of 461\n",
      "Downloading 385 out of 461\n",
      "Downloading 386 out of 461\n",
      "Downloading 387 out of 461\n",
      "Downloading 388 out of 461\n",
      "Downloading 389 out of 461\n",
      "Downloading 390 out of 461\n",
      "Downloading 391 out of 461\n",
      "Downloading 392 out of 461\n",
      "Downloading 393 out of 461\n",
      "Downloading 394 out of 461\n",
      "Downloading 395 out of 461\n",
      "Downloading 396 out of 461\n",
      "Downloading 397 out of 461\n",
      "Downloading 398 out of 461\n",
      "Downloading 399 out of 461\n",
      "Downloading 400 out of 461\n",
      "Downloading 401 out of 461\n",
      "Downloading 402 out of 461\n",
      "Downloading 403 out of 461\n",
      "Downloading 404 out of 461\n",
      "Downloading 405 out of 461\n",
      "Downloading 406 out of 461\n",
      "Downloading 407 out of 461\n",
      "Downloading 408 out of 461\n",
      "Downloading 409 out of 461\n",
      "Downloading 410 out of 461\n",
      "Downloading 411 out of 461\n",
      "Downloading 412 out of 461\n",
      "Downloading 413 out of 461\n",
      "Downloading 414 out of 461\n",
      "Downloading 415 out of 461\n",
      "Downloading 416 out of 461\n",
      "Downloading 417 out of 461\n",
      "Downloading 418 out of 461\n",
      "Downloading 419 out of 461\n",
      "Downloading 420 out of 461\n",
      "Downloading 421 out of 461\n",
      "Downloading 422 out of 461\n",
      "Downloading 423 out of 461\n",
      "Downloading 424 out of 461\n",
      "Downloading 425 out of 461\n",
      "Downloading 426 out of 461\n",
      "Downloading 427 out of 461\n",
      "Downloading 428 out of 461\n",
      "Downloading 429 out of 461\n",
      "Downloading 430 out of 461\n",
      "Downloading 431 out of 461\n",
      "Downloading 432 out of 461\n",
      "Downloading 433 out of 461\n",
      "Downloading 434 out of 461\n",
      "Downloading 435 out of 461\n",
      "Downloading 436 out of 461\n",
      "Downloading 437 out of 461\n",
      "Downloading 438 out of 461\n",
      "Downloading 439 out of 461\n",
      "Downloading 440 out of 461\n",
      "Downloading 441 out of 461\n",
      "Downloading 442 out of 461\n",
      "Downloading 443 out of 461\n",
      "Downloading 444 out of 461\n",
      "Downloading 445 out of 461\n",
      "Downloading 446 out of 461\n",
      "Downloading 447 out of 461\n",
      "Downloading 448 out of 461\n",
      "Downloading 449 out of 461\n",
      "Downloading 450 out of 461\n",
      "Downloading 451 out of 461\n",
      "Downloading 452 out of 461\n",
      "Downloading 453 out of 461\n",
      "Downloading 454 out of 461\n",
      "Downloading 455 out of 461\n",
      "Downloading 456 out of 461\n",
      "Downloading 457 out of 461\n",
      "Downloading 458 out of 461\n",
      "Downloading 459 out of 461\n",
      "Downloading 460 out of 461\n",
      "Downloading 461 out of 461\n",
      "CPU times: user 14.6 s, sys: 1.94 s, total: 16.5 s\n",
      "Wall time: 8min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download each document in turn\n",
    "request_headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "for i, row in enumerate(data):\n",
    "    row_id = row[-1]\n",
    "    download_link = row[-2]\n",
    "    print(f\"Downloading {i + 1} out of {len(data)}\")\n",
    "    \n",
    "    try:\n",
    "        save_pdf(download_link, os.path.join(RAW_DIR, f\"{row_id}.pdf\"), headers=request_headers)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download and save for ID {row_id}, {download_link} : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe with document metadata\n",
    "\n",
    "For each document, store the metadata found in every result row at https://www.globalr2p.org/resources/?s&filter%5B0%5D=official-statement&filter%5B1%5D=government-statement&tax=resource_type plus the `id` assigned to every document when scraping the download links.\n",
    "\n",
    "The `id` is important since for every document the corresponding PDF is saved in a file under that name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Info:\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 461 entries, 0 to 460\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Title   461 non-null    object        \n",
      " 1   Type    461 non-null    object        \n",
      " 2   Date    461 non-null    datetime64[ns]\n",
      " 3   Source  461 non-null    object        \n",
      " 4   link    461 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 21.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Statement by Switzerland at the 2017 UN Genera...</td>\n",
       "      <td>Government Statement</td>\n",
       "      <td>2017-09-06</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>https://www.globalr2p.org/wp-content/uploads/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Statement by Estonia on behalf of Latvia and L...</td>\n",
       "      <td>Government Statement</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>https://www.globalr2p.org/wp-content/uploads/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title                  Type  \\\n",
       "id                                                                             \n",
       "117  Statement by Switzerland at the 2017 UN Genera...  Government Statement   \n",
       "374  Statement by Estonia on behalf of Latvia and L...  Government Statement   \n",
       "\n",
       "          Date       Source                                               link  \n",
       "id                                                                              \n",
       "117 2017-09-06  Switzerland  https://www.globalr2p.org/wp-content/uploads/2...  \n",
       "374 2014-09-08      Estonia  https://www.globalr2p.org/wp-content/uploads/2...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Storing metadata in ./gr2p/globalr2p_docs_data.csv\n"
     ]
    }
   ],
   "source": [
    "df_speeches = pd.DataFrame(data, columns=headers)\n",
    "df_speeches[\"Date\"] = pd.to_datetime(df_speeches[\"Date\"])\n",
    "\n",
    "df_speeches.set_index(\"id\", inplace=True)\n",
    "print(\"------\\nInfo:\\n\\n\")\n",
    "display(df_speeches.info())\n",
    "print(\"\\n\\n------\\nSample:\")\n",
    "display(df_speeches.sample(2))\n",
    "\n",
    "metadata_file = os.path.join(GR2P_DIR, \"globalr2p_docs_data.csv\")\n",
    "print(f\"\\n\\nStoring metadata in {metadata_file}\")\n",
    "df_speeches.to_csv(metadata_file);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
